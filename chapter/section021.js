export const QA021 = [
  ["기존의 관리 방법이나 분석 체계로는 처리하기 어려운 막대한 양의 정형 또는 비정형 데이터 집합", "빅데이터", "Big Data"],
  ["빅데이터가 주목받고 있는 이유는 기업이나 정부, 포털 등이 빅데이터를 효과적으로 분석함으로써 미래를 예측해 최적의 대응 방안을 찾고, 이를 수익으로 연결하여 새로운 가치를 창출하기 때문임", "빅데이터", "Big Data"],
  ["다양한 채널에서 소비자와 상호 작용을 통해 생성된 것으로, 기업 마케팅에 있어 효율적이고 다양한 데이터이며, 이전에 사용하지 않거나 알지 못했던 새로운 데이터나 기존 데이터에 새로운 가치가 더해진 데이터", "브로드 데이터", "Broad Data"],
  ["일련의 데이터를 정의하고 설명해 주는 데이터", "메타 데이터", "Meta Daata"],
  ["컴퓨터에서는 데이터 사전의 내용, 스키마 등을 의미하고 HTML 문서에서는 메타 태그 내의 내용을 의미함", "메타 데이터", "Meta Data"],
  ["디지털 정보 자원을 장기적으로 보존하기 위한 작업으로 아날로그 콘텐츠는 디지털로 변환한 후 압축해서 저장하고, 디지털 콘텐츠도 체계적으로 분류하고 메타 데이터를 만들어 DB화하는 작업임", "디지털 아카이빙", "Digital Archiving"],
  ["오픈 소스를 기반으로 한 분산 컴퓨팅 플랫폼으로 구글, 야후 등에 적용되고 있음", "하둡", "Hadoop"],
  ["일반 PC급 컴퓨터들로 가상화된 대형 스토리지를 형성하고 그 안에 보관된 거대한 데이터 세트를 병렬로 처리할 수 있도록 개발된 자바 소프트웨어 프레임워크", "하둡", "Hadoop"],
  ["대용량 데이터를 분산 처리하기 위한 목적으로 개발된 프로그래밍 모델로, 임의의 순서로 정렬된 데이터를 분산 처리하고 이를 다시 합치는 과정", "맵리듀스", "MapReduce"],
  ["Google에 의해 고안되었으며, 대표적인 대용량 데이터 처리를 위한 병렬 처리 기법으로 많이 사용되고 있음", "맵리듀스", "MapReduce"],
  ["흩어져 있는 데이터를 연관성 있는 데이터 분류로 묶는 Map 작업을 수행한 후 중복 데이터를 제거하고 원하는 데이터를 추출하는 Reduce 작업을 수행함", "맵리듀스", "MapReduce"],
  ["오픈 소스 기반 분산 컴퓨팅 플랫폼인 아파치 하둡(Apache Hadoop) 기반의 분산 데이터 웨어하우스 프로젝트", "타조", "Tajo"],
  ["데이터를 삭제하는 것이 아니라 압축하고, 중복된 정보는 중복을 배제하고, 새로운 기준에 따라 나누어 저장하는 작업", "데이터 다이어트", "Data Diet"],
  ["대량의 데이터를 분석하여 데이터에 내재된 변수 사이의 상호 관계를 규명하여 일정한 패턴을 찾아내는 기법", "데이터 마이닝", "Data Mining"],
  ["다차원으로 이루어진 데이터로부터 통계적인 요약 정보를 분석하여 의사결정에 활용하는 방식으로 연산에는 Roll-up, Drill-down, Drill-through, Drill-across, Pivoting, Slicing, Dicing 등이 있음", "OLAP", "Online Analytical Processing"],
  ["리스트의 한쪽 끝으로만 자료의 삽입, 삭제 작업이 이루어지는 자료 구조로 후입선출(LIFO; Last In First Out) 방식으로 자료를 처리함", "스택", "Stack"],
  ["리스트의 한쪽에서는 삽입 작업이 이루어지고 다른 한쪽에서는 삭제 작업이 이루어지도록 구성한 자료 구조로 선입선출(FIFO; First In First Out) 방식으로 처리함", "큐", "Queue"],
  ["함수적 종속성 등의 종속성 이론을 이용하여 잘못 설계된 관계형 스키마를 더 작은 속성의 세트로 쪼개어 바람직한 스키마로 만들어 가는 과정", "정규화", "Normalization"],
  ["시스템의 성능 향상, 개발 및 운영의 편의성 등을 위해 정규화된 데이터 모델을 통합 중복, 분리하는 과정으로, 의도적으로 정규화 원칙을 위배하는 행위", "반정규화", "Denormalization"],
  ["정규화를 거치지 않으면 데이터베이스 내에 데이터들이 불필요하게 중복되어 릴레이션 조작 시 예기치 못한 곤란한 현상이 발생하는데, 이를 (     )라고 하며, 삽입 (     ), 삭제 (     ), 갱신 (     )이 있음", "이상", "Anomally"],
  ["데이터 레코드를 빠르게 접근하기 위해 <키 값, 포인터> 쌍으로 구성되는 데이터 구조", "인덱스", "Index"],
  ["사용자에게 접근이 허용된 자료만을 제한적으로 보여주기 위해 하나 이상의 기본 테이블로부터 유도된 이름을 가지는 가상 테이블", "뷰", "View"],
  ["데이터베이스에서 대용량의 테이블이나 인덱스를 나누는 작은 논리적 단위", "파티션", "Partition"],
  ["관계형 데이터베이스에서 원하는 정보와 그 정보를 검색하기 위해서 어떻게 유도하는가를 기술하는 절차적인 언어", "관계대수"],
  ["관계 데이터의 연산을 표현하는 방법으로, 관계 데이터 모델의 제안자인 코드(E. F. Codd)가 수학의 Predication Calculus(술어 해석)에 기반을 두고 관계 데이터베이스를 위해 제안했음", "관계해석"],
  ["릴레이션을 구성하는 속성들 중에서 튜플을 유일하게 식별하기 위해 사용하는 속설들의 부분집합, 즉 기본치로 사용할 수 있는 속성들을 의미하며 릴레이션에 있는 모든 튜플에 대해서 유일성과 최소성을 만족시켜야 함", "후보키", "Candidate Key"],
  ["후보키 중에서 특별히 선정된 주키(Main Key)로, 중복된 값을 가질 수 없음", "기본키", "Primary Key"],
  ["후보키가 둘 이상일 때 기본키를 제외한 나머지 후보키를 의미하며, 보조키라고도 함", "대체키", "Alternate Key"],
  ["한 릴레이션 내에 있는 속성들의 집합으로 구성된 키로, 릴레이션을 구성하는 모든 튜플에 대해 유일성은 만족시키지만, 최소성은 만족시키지 못함", "슈퍼키", "Super Key"],
  ["다른 릴레이션의 기본키를 참조하는 속성 또는 속성들의 집합을 의미함", "외래키", "Foreign Key"],
  ["기본 테이블의 기본키를 구성하는 어떤 속성도 Null 값이나 중복값을 가질 수 없다는 규정", "개체 무결성", "Entity Integrity"],
  ["외래키 값은 Null이거나 참조 릴레이션의 기본키 값과 동일해야 함. 즉 릴레이션은 참조할 수 없는 외래키 값을 가질 수 없다는 규정", "참조 무결성", "Referential Integrity"]
];